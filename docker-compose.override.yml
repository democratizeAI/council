version: '3.8'

services:
  council-api:
    # No environment overrides - use defaults for real TinyLlama loading
    environment: {}

  mock-api:
    image: python:3.11-slim
    command: sh -c "pip install fastapi uvicorn && python /app/mockfast.py"
    volumes:
      - ./mockfast.py:/app/mockfast.py
    ports:
      - "9000:8000"
    environment:
      UVICORN_TIMEOUT_KEEP_ALIVE: "5"
    profiles: ["bypass"]

  # --- Canary service (5% traffic on GPU-1) ---
  api-canary:
    build: 
      context: .
      dockerfile: Dockerfile.canary
    container_name: api-canary
    ports:
      - "8001:8000"
    environment:
      GPU_AUX_ID: "1"                # ensure heavy models hit GPU-1
      CANARY_MODE: "true"            # flag used by Prom counters
      CUDA_VISIBLE_DEVICES: "1"
      REDIS_URL: "redis://redis:6379/0"
      SWARM_PROFILE: "canary"
      COUNCIL_TRAFFIC_PERCENT: 5
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              device_ids: ["1"]      # bind to GPU-1 only
        limits:
          memory: 8g
          cpus: "4.0"
    volumes:
      - ./memory:/app/memory
      - ./logs:/app/logs
    depends_on:
      - redis
    restart: on-failure:3
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 5s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    networks:
      - default

  # Prometheus Pushgateway for chaos testing
  pushgw:
    image: prom/pushgateway:latest
    container_name: pushgateway
    ports:
      - "9091:9091"
    restart: on-failure:3
    command:
      - '--web.listen-address=0.0.0.0:9091'
      - '--web.telemetry-path=/metrics'
      - '--web.external-url=http://localhost:9091'
      - '--log.level=info'
    deploy:
      resources:
        limits:
          memory: 256m
          cpus: "0.5"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9091/-/healthy"]
      interval: 15s
      timeout: 3s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "2"
    networks:
      - default

  # Reward model trainer - runs nightly at 02:00
  reward-trainer:
    build: .
    container_name: reward-trainer
    volumes:
      - ./preference_model:/app/preference_model
      - ./scripts:/app/scripts
      - reward_data:/opt/lumina/reward
    environment:
      - PYTHONUNBUFFERED=1
    depends_on:
      - redis
      - pushgw
    restart: unless-stopped
    command: >
      bash -c "
        apt-get update && apt-get install -y cron jq &&
        echo '0 2 * * * cd /app && bash scripts/nightly_reward_train.sh >> /var/log/reward_train.log 2>&1' | crontab - &&
        echo '0 * * * * cd /app && python preference_model/dataset.py >> /var/log/pair_builder.log 2>&1' | crontab - &&
        cron && tail -f /var/log/cron.log /var/log/reward_train.log /var/log/pair_builder.log
      "
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    networks:
      - default

  # Pattern-Miner service  
  pattern-miner:
    build: .
    command: python pattern_miner.py
    environment:
      CUDA_VISIBLE_DEVICES: "0"
      REDIS_URL: "redis://redis:6379/0"
    depends_on:
      - redis
    restart: on-failure:3
    deploy:
      resources:
        limits:
          memory: 1g
          cpus: "1.0"
    networks:
      - default

volumes:
  reward_data:
    driver: local

networks:
  default:
    name: council-network
    external: true 