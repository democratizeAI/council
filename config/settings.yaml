cloud:
  budget_usd: 10.0
  enabled: true
  providers:
    mistral:
      priority: 1
      timeout_ms: 5000
    openai:
      priority: 2
      timeout_ms: 8000
logging:
  file: logs/autogen.log
  format: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
  level: INFO
memory:
  dimension: 384
  max_entries: 10000
  persist_every: 100
  provider: faiss
  enabled: true
  redis_channel: "scratchpad_v2"
  cache_size: 1000
  episodic_limit: 240  # tokens for episodic context
sandbox:
  cpu_limit: 1.0
  docker:
    image: agent-sandbox:latest
    network: none
    remove_after: true
    volumes: []
    working_dir: /tmp/execution
  enabled: true
  firejail:
    no_network: true
    private_tmp: true
    profile: sandbox/profile.conf
  memory_limit_mb: 256
  provider: wsl
  timeout_seconds: 5
  wsl:
    distro: Ubuntu
    user: sandbox

qdrant:
  collection: "lumina_mem_v2"
  dimension: 768
  hnsw_m: 32
  ef_construction: 256

gpu:
  # Preserve Phase 1 optimizations
  quantization: true
  attention_backend: "sdpa"
  mixed_precision: true
  max_batch_size: 4

router:
  dynamic_batch:
    max_tokens: 2048  # Conservative to preserve GPU gains
    timeout_ms: 100
  
  confidence_gates:
    to_synth: 0.45    # From Phase 1 tuning
    to_premium: 0.20

performance:
  target_tokens_per_sec: 25   # Adjusted for memory overhead
  target_gpu_util: 35         # Preserve Phase 1 achievement
  max_latency_ms: 1500
