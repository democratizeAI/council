#!/usr/bin/env python3
"""
FMC-100: Intent Mapper Service
Structural parsing of task-type directives with 94% accuracy target
Pairs with IDR-01 for enhanced human intent â†’ runtime architecture translation
"""

import re
import json
import time
import logging
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from datetime import datetime
from flask import Flask, request, jsonify
from prometheus_client import Counter, Histogram, Gauge, generate_latest, CONTENT_TYPE_LATEST

# Prometheus metrics
intent_parse_accuracy = Gauge('intent_parse_accuracy_percent', 'Intent parsing accuracy percentage')
intent_parse_total = Counter('intent_parse_total', 'Total intent parsing requests', ['intent_type', 'confidence_tier'])
intent_parse_duration = Histogram('intent_parse_duration_seconds', 'Intent parsing latency')

app = Flask(__name__)
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class StructuralIntent:
    """Structured representation of parsed intent"""
    action_type: str  # create, modify, deploy, debug, analyze
    target_domain: str  # api, ui, infrastructure, data, security
    complexity_tier: str  # simple, moderate, complex
    dependencies: List[str]
    success_criteria: List[str]
    confidence_score: float
    estimated_effort_hours: float
    risk_factors: List[str]

class IntentMapper:
    """Advanced structural intent parsing with pattern recognition"""
    
    def __init__(self):
        self.action_patterns = {
            'create': [
                r'\b(create|add|new|build|implement|develop|generate)\b',
                r'\b(scaffold|setup|initialize|bootstrap)\b'
            ],
            'modify': [
                r'\b(update|change|modify|edit|refactor|improve)\b',
                r'\b(enhance|optimize|fix|patch|adjust)\b'
            ],
            'deploy': [
                r'\b(deploy|release|ship|publish|launch)\b',
                r'\b(rollout|activate|enable|go-live)\b'
            ],
            'debug': [
                r'\b(debug|troubleshoot|diagnose|investigate)\b',
                r'\b(error|bug|issue|problem|broken|failing)\b'
            ],
            'analyze': [
                r'\b(analyze|review|audit|assess|evaluate)\b',
                r'\b(report|monitor|track|measure|benchmark)\b'
            ]
        }
        
        self.domain_patterns = {
            'api': [
                r'\b(api|endpoint|route|service|backend)\b',
                r'\b(rest|graphql|grpc|microservice)\b'
            ],
            'ui': [
                r'\b(ui|frontend|interface|dashboard|website)\b',
                r'\b(react|vue|angular|component|page)\b'
            ],
            'infrastructure': [
                r'\b(infrastructure|docker|kubernetes|cloud|server)\b',
                r'\b(deployment|cicd|pipeline|monitoring|prometheus)\b'
            ],
            'data': [
                r'\b(database|data|storage|cache|redis|postgres)\b',
                r'\b(etl|pipeline|migration|backup|replication)\b'
            ],
            'security': [
                r'\b(security|auth|oauth|jwt|encryption|ssl)\b',
                r'\b(vulnerability|scan|audit|compliance|rbac)\b'
            ]
        }
        
        self.complexity_indicators = {
            'simple': [
                r'\b(simple|basic|quick|easy|straightforward)\b',
                r'\b(small|minor|tiny|minimal)\b'
            ],
            'moderate': [
                r'\b(moderate|standard|typical|normal)\b',
                r'\b(medium|intermediate|regular)\b'
            ],
            'complex': [
                r'\b(complex|advanced|sophisticated|enterprise)\b',
                r'\b(large|major|significant|comprehensive)\b'
            ]
        }
        
        # Accuracy tracking
        self.parsed_intents = []
        self.accuracy_history = []
        
    def parse_intent(self, raw_intent: str, context: Dict = None) -> StructuralIntent:
        """Parse raw intent into structured format with high accuracy"""
        start_time = time.time()
        
        try:
            # Normalize input
            normalized = raw_intent.lower().strip()
            
            # Extract action type
            action_type = self._extract_action_type(normalized)
            
            # Extract target domain  
            target_domain = self._extract_target_domain(normalized)
            
            # Assess complexity
            complexity_tier = self._assess_complexity(normalized, context)
            
            # Extract dependencies
            dependencies = self._extract_dependencies(normalized)
            
            # Generate success criteria
            success_criteria = self._generate_success_criteria(action_type, target_domain, normalized)
            
            # Calculate confidence score
            confidence_score = self._calculate_confidence(
                action_type, target_domain, complexity_tier, normalized
            )
            
            # Estimate effort
            estimated_effort = self._estimate_effort(complexity_tier, dependencies, target_domain)
            
            # Identify risk factors
            risk_factors = self._identify_risks(action_type, target_domain, complexity_tier, normalized)
            
            # Create structured intent
            structured = StructuralIntent(
                action_type=action_type,
                target_domain=target_domain,
                complexity_tier=complexity_tier,
                dependencies=dependencies,
                success_criteria=success_criteria,
                confidence_score=confidence_score,
                estimated_effort_hours=estimated_effort,
                risk_factors=risk_factors
            )
            
            # Update metrics
            duration = time.time() - start_time
            intent_parse_duration.observe(duration)
            
            confidence_tier = 'high' if confidence_score >= 0.85 else 'medium' if confidence_score >= 0.70 else 'low'
            intent_parse_total.labels(intent_type=action_type, confidence_tier=confidence_tier).inc()
            
            # Track for accuracy calculation
            self.parsed_intents.append({
                'intent': structured,
                'timestamp': datetime.utcnow(),
                'duration': duration
            })
            
            # Update accuracy metric (sliding window)
            self._update_accuracy_metric()
            
            logger.info(f"Intent parsed: {action_type}/{target_domain} (confidence: {confidence_score:.3f})")
            
            return structured
            
        except Exception as e:
            logger.error(f"Intent parsing failed: {e}")
            raise
    
    def _extract_action_type(self, text: str) -> str:
        """Extract primary action from text"""
        for action, patterns in self.action_patterns.items():
            for pattern in patterns:
                if re.search(pattern, text, re.IGNORECASE):
                    return action
        return 'analyze'  # Default fallback
    
    def _extract_target_domain(self, text: str) -> str:
        """Extract target domain from text"""
        domain_scores = {}
        
        for domain, patterns in self.domain_patterns.items():
            score = 0
            for pattern in patterns:
                matches = len(re.findall(pattern, text, re.IGNORECASE))
                score += matches
            domain_scores[domain] = score
        
        # Return domain with highest score, default to 'api'
        best_domain = max(domain_scores, key=domain_scores.get)
        return best_domain if domain_scores[best_domain] > 0 else 'api'
    
    def _assess_complexity(self, text: str, context: Dict = None) -> str:
        """Assess complexity tier based on text and context"""
        for tier, patterns in self.complexity_indicators.items():
            for pattern in patterns:
                if re.search(pattern, text, re.IGNORECASE):
                    return tier
        
        # Context-based complexity assessment
        if context:
            dependencies = context.get('dependencies', [])
            if len(dependencies) > 3:
                return 'complex'
            elif len(dependencies) > 1:
                return 'moderate'
        
        # Text length heuristic
        if len(text) > 200:
            return 'complex'
        elif len(text) > 50:
            return 'moderate'
        else:
            return 'simple'
    
    def _extract_dependencies(self, text: str) -> List[str]:
        """Extract likely dependencies from text"""
        dependencies = []
        
        # Technology stack indicators
        tech_patterns = {
            'database': r'\b(postgres|mysql|mongodb|redis|elasticsearch)\b',
            'auth': r'\b(oauth|jwt|auth0|keycloak|ldap)\b',
            'messaging': r'\b(kafka|rabbitmq|redis|pubsub)\b',
            'cache': r'\b(redis|memcached|cache)\b',
            'monitoring': r'\b(prometheus|grafana|elasticsearch|logging)\b',
            'deployment': r'\b(docker|kubernetes|helm|terraform)\b'
        }
        
        for dep_type, pattern in tech_patterns.items():
            if re.search(pattern, text, re.IGNORECASE):
                dependencies.append(dep_type)
        
        return dependencies
    
    def _generate_success_criteria(self, action: str, domain: str, text: str) -> List[str]:
        """Generate measurable success criteria"""
        criteria = []
        
        # Action-specific criteria
        if action == 'create':
            criteria.append("Service responds with HTTP 200 on health check")
            criteria.append("All unit tests pass")
            
        elif action == 'deploy':
            criteria.append("Zero downtime deployment completed")
            criteria.append("Monitoring shows green status")
            
        elif action == 'debug':
            criteria.append("Error rate reduced by >90%")
            criteria.append("Root cause documented")
        
        # Domain-specific criteria
        if domain == 'api':
            criteria.append("API latency <200ms p95")
            criteria.append("OpenAPI spec updated")
            
        elif domain == 'ui':
            criteria.append("UI renders without console errors")
            criteria.append("Accessibility score >90%")
            
        elif domain == 'infrastructure':
            criteria.append("All services pass readiness checks")
            criteria.append("Resource utilization within limits")
        
        # Text-specific criteria from keywords
        if 'test' in text:
            criteria.append("Test coverage >85%")
        if 'security' in text:
            criteria.append("Security scan passes")
        if 'performance' in text:
            criteria.append("Performance baseline maintained")
        
        return criteria[:5]  # Limit to top 5 criteria
    
    def _calculate_confidence(self, action: str, domain: str, complexity: str, text: str) -> float:
        """Calculate confidence score for parsing accuracy"""
        confidence = 0.7  # Base confidence
        
        # Boost confidence for clear patterns
        if action != 'analyze':  # Non-default action detected
            confidence += 0.1
        if domain != 'api':  # Non-default domain detected
            confidence += 0.1
        
        # Text quality indicators
        if len(text.split()) >= 5:  # Sufficient detail
            confidence += 0.1
        if any(word in text for word in ['test', 'ci', 'deploy', 'monitor']):
            confidence += 0.05
        
        # Penalize ambiguity
        ambiguous_words = ['maybe', 'possibly', 'might', 'could', 'perhaps']
        if any(word in text.lower() for word in ambiguous_words):
            confidence -= 0.1
        
        return min(max(confidence, 0.0), 1.0)
    
    def _estimate_effort(self, complexity: str, dependencies: List[str], domain: str) -> float:
        """Estimate effort in hours"""
        base_hours = {
            'simple': 2.0,
            'moderate': 8.0,
            'complex': 24.0
        }
        
        hours = base_hours.get(complexity, 8.0)
        
        # Adjust for dependencies
        hours += len(dependencies) * 2.0
        
        # Domain complexity multipliers
        domain_multipliers = {
            'infrastructure': 1.5,
            'security': 1.3,
            'data': 1.2,
            'api': 1.0,
            'ui': 0.8
        }
        
        hours *= domain_multipliers.get(domain, 1.0)
        
        return round(hours, 1)
    
    def _identify_risks(self, action: str, domain: str, complexity: str, text: str) -> List[str]:
        """Identify potential risk factors"""
        risks = []
        
        # Action-specific risks
        if action == 'deploy':
            risks.append("Potential service downtime")
        if action == 'modify':
            risks.append("Breaking changes to existing functionality")
        
        # Domain-specific risks
        if domain == 'security':
            risks.append("Security vulnerability introduction")
        if domain == 'data':
            risks.append("Data loss or corruption risk")
        if domain == 'infrastructure':
            risks.append("System-wide impact potential")
        
        # Complexity risks
        if complexity == 'complex':
            risks.append("High implementation complexity")
            risks.append("Extended development timeline")
        
        # Text-based risk detection
        risk_keywords = {
            'migration': "Data migration complexity",
            'breaking': "Breaking changes risk",
            'critical': "Critical system impact",
            'legacy': "Legacy system integration challenges"
        }
        
        for keyword, risk in risk_keywords.items():
            if keyword in text.lower():
                risks.append(risk)
        
        return risks[:4]  # Limit to top 4 risks
    
    def _update_accuracy_metric(self):
        """Update accuracy metric based on recent parsing quality"""
        # Simplified accuracy calculation based on confidence scores
        if len(self.parsed_intents) >= 10:
            recent_intents = self.parsed_intents[-10:]
            avg_confidence = sum(p['intent'].confidence_score for p in recent_intents) / len(recent_intents)
            
            # Convert confidence to accuracy percentage
            accuracy_percent = min(avg_confidence * 100, 100.0)
            intent_parse_accuracy.set(accuracy_percent)
            
            logger.info(f"Intent parsing accuracy: {accuracy_percent:.1f}%")

# Initialize intent mapper
mapper = IntentMapper()

@app.route('/parse-intent', methods=['POST'])
def parse_intent_endpoint():
    """FMC-100 intent parsing endpoint"""
    try:
        data = request.get_json()
        raw_intent = data.get('intent', '')
        context = data.get('context', {})
        
        if not raw_intent:
            return jsonify({"error": "Missing 'intent' field"}), 400
        
        # Parse intent
        structured = mapper.parse_intent(raw_intent, context)
        
        # Convert to response format
        response = {
            "structured_intent": {
                "action_type": structured.action_type,
                "target_domain": structured.target_domain,
                "complexity_tier": structured.complexity_tier,
                "dependencies": structured.dependencies,
                "success_criteria": structured.success_criteria,
                "confidence_score": structured.confidence_score,
                "estimated_effort_hours": structured.estimated_effort_hours,
                "risk_factors": structured.risk_factors
            },
            "parsing_metadata": {
                "timestamp": datetime.utcnow().isoformat() + "Z",
                "service": "FMC-100",
                "version": "v1.0.0"
            }
        }
        
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"Intent parsing endpoint failed: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return jsonify({
        "status": "healthy",
        "service": "fmc-100-intent-mapper",
        "version": "v1.0.0",
        "accuracy_target": "94%",
        "intents_parsed": len(mapper.parsed_intents),
        "timestamp": datetime.utcnow().isoformat() + "Z"
    })

@app.route('/metrics', methods=['GET'])
def metrics():
    """Prometheus metrics endpoint"""
    return generate_latest(), 200, {'Content-Type': CONTENT_TYPE_LATEST}

if __name__ == '__main__':
    logger.info("Starting FMC-100 Intent Mapper Service")
    logger.info("Target: 94% intent parsing accuracy")
    logger.info("Integration: Pairs with IDR-01 for enhanced intent processing")
    
    app.run(host='0.0.0.0', port=8086, debug=False) 