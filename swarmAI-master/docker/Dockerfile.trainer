FROM pytorch/pytorch:2.1.0-cuda12.1-cudnn8-devel

# Build arguments
ARG PYTORCH_VERSION=2.1.0-cuda12.1-cudnn8-devel

# Install system dependencies
RUN apt-get update && apt-get install -y \
    git \
    curl \
    build-essential \
    psutil \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Install training dependencies with latest versions
RUN pip install --no-cache-dir \
    transformers==4.35.0 \
    datasets==2.14.0 \
    peft==0.6.0 \
    accelerate==0.24.0 \
    bitsandbytes==0.41.0 \
    wandb==0.15.0 \
    scikit-learn==1.3.0 \
    tensorboard==2.14.0 \
    protobuf==3.20.3 \
    sentencepiece==0.1.99 \
    safetensors==0.4.0 \
    pyyaml==6.0 \
    tqdm==4.66.0 \
    psutil==5.9.0 \
    prometheus-client==0.18.0

# Copy training scripts
COPY trainer/trainer_worker.py .
COPY scripts/lora_trainer.py ./scripts/
COPY scripts/validation.py ./scripts/
COPY scripts/monitor_evolution.py ./scripts/

# Create directories with proper permissions
RUN mkdir -p jobs datasets models loras logs scripts && \
    chmod 755 jobs datasets models loras logs scripts

# Create enhanced training entrypoint with metrics
RUN echo '#!/bin/bash\n\
echo "ðŸ”¥ Starting LoRA Trainer Worker (Evolution Branch)"\n\
echo "GPU Status:"\n\
nvidia-smi\n\
echo "Memory Status:"\n\
free -h\n\
echo "Starting training loop with metrics..."\n\
python3 trainer_worker.py --watch-queue --metrics-port 8080\n\
' > /start_trainer.sh && chmod +x /start_trainer.sh

# Create metrics endpoint script
RUN echo '#!/usr/bin/env python3\n\
import time\n\
import psutil\n\
from prometheus_client import start_http_server, Gauge, Counter\n\
\n\
# Metrics\n\
training_jobs_total = Counter("training_jobs_total", "Total training jobs processed")\n\
training_jobs_active = Gauge("training_jobs_active", "Currently active training jobs")\n\
gpu_memory_usage = Gauge("gpu_memory_usage_bytes", "GPU memory usage")\n\
\n\
def collect_metrics():\n\
    while True:\n\
        # Collect system metrics\n\
        memory = psutil.virtual_memory()\n\
        # Add GPU metrics collection here\n\
        time.sleep(30)\n\
\n\
if __name__ == "__main__":\n\
    start_http_server(8080)\n\
    collect_metrics()\n\
' > /metrics_server.py && chmod +x /metrics_server.py

# Non-root user
RUN useradd -m -u 1000 trainer && \
    chown -R trainer:trainer /app
USER trainer

# Environment variables for training optimization
ENV PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
ENV CUDA_LAUNCH_BLOCKING=1
ENV TOKENIZERS_PARALLELISM=false
ENV PYTHONUNBUFFERED=1
ENV TRAINER_METRICS_PORT=8080

# Health check for trainer with process monitoring
HEALTHCHECK --interval=60s --timeout=30s --start-period=10s --retries=3 \
    CMD python3 -c "import psutil; exit(0 if any('trainer_worker' in p.name() for p in psutil.process_iter()) else 1)"

# Expose metrics port
EXPOSE 8080

# Start the trainer worker with enhanced monitoring
CMD ["/start_trainer.sh"] 